2024-04-09 10:22:39,698 - root - INFO - Namespace(agg_method='attn', attn_mode='prod', bs=100, data='wikipedia', drop_out=0.1, gpu=0, lr=0.0001, n_degree=20, n_epoch=50, n_head=2, n_layer=1, node_dim=100, prefix='wiki100', time='time', time_dim=100, uniform=True)
2024-04-09 10:22:40,558 - module - INFO - Aggregation uses attention model
2024-04-09 10:22:40,574 - module - INFO - Using scaled prod attention
2024-04-09 10:22:40,574 - module - INFO - Using time encoding
2024-04-09 10:22:42,796 - root - INFO - num of training instances: 81029
2024-04-09 10:22:42,796 - root - INFO - num of batches per epoch: 811
2024-04-09 10:22:42,799 - root - INFO - start 0 epoch
2024-04-09 10:23:10,022 - root - INFO - epoch: 0
2024-04-09 10:23:10,022 - root - INFO - total memory use: 308.15 MB
2024-04-09 10:23:10,022 - root - INFO - train time: 14.20 s
2024-04-09 10:23:10,022 - root - INFO - Epoch mean loss: 1.0275901609666545
2024-04-09 10:23:10,022 - root - INFO - train acc: 0.7266, val acc: 0.7082, new node val acc: 0.7168
2024-04-09 10:23:10,022 - root - INFO - train auc: 0.8134, val auc: 0.7897, new node val auc: 0.8026
2024-04-09 10:23:10,022 - root - INFO - train ap: 0.8189, val ap: 0.8066, new node val ap: 0.8210
2024-04-09 10:23:10,023 - root - INFO - train recall: 0.7455, val recall: 0.7415, new node val recall: 0.7530
2024-04-09 10:23:10,695 - root - INFO - start 1 epoch
